{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxywIvRBlaO7Urg0jqsbSV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Z8GDoayR5Nqw"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","import joblib\n","\n","# Function to generate linear data\n","def generate_linear_data(num_samples, slope_range=(-5, 5), intercept_range=(-10, 10), noise=0.5):\n","    X = np.random.uniform(-100, 100, num_samples)\n","    slope = np.random.uniform(*slope_range)\n","    intercept = np.random.uniform(*intercept_range)\n","    y = slope * X + intercept + np.random.normal(0, noise, num_samples)\n","    return X, y\n","\n","# Generate dataset\n","num_samples = 1000\n","slope_range = (-5, 5)\n","intercept_range = (-10, 10)\n","noise = 0.5\n","X, y = generate_linear_data(num_samples, slope_range, intercept_range, noise)\n","\n","# Save dataset to CSV\n","np.savetxt('linear_dataset.csv', np.column_stack((X, y)), delimiter=',', header='X,y', comments='')\n","\n","# Load dataset\n","df = pd.read_csv('linear_dataset.csv')\n","X = df[['X']]  # Features\n","y = df['y']    # Target variable\n","\n","\n","# Print X and y coordinates\n","print(\"X coordinates:\")\n","print(X.head())\n","\n","print(\"\\ny coordinates:\")\n","print(y.head())\n","\n","# Split dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train the linear regression model\n","model = LinearRegression()\n","model.fit(X_train, y_train)\n","\n","# Evaluate the model\n","train_score = model.score(X_train, y_train)\n","test_score = model.score(X_test, y_test)\n","\n","print(\"\\nTraining R^2 score:\", train_score)\n","print(\"Testing R^2 score:\", test_score)\n","\n","\n","\n","\n","# Save the trained model to a file\n","joblib.dump(model, 'linear_regression_model.pkl')\n","\n","print(\"Model saved successfully.\")\n","\n"]},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","\n","# Assuming X and y are your features and target variable\n","# Generate dataset as in your previous code\n","num_samples = 1000\n","slope_range = (-5, 5)\n","intercept_range = (-10, 10)\n","noise = 0.5\n","X, y = generate_linear_data(num_samples, slope_range, intercept_range, noise)\n","\n","# Concatenate features and target variable\n","data = np.column_stack((X, y))\n","\n","# Apply K-means clustering\n","kmeans = KMeans(n_clusters=3)  # Adjust number of clusters as needed\n","kmeans.fit(data)\n","\n","# Get cluster labels\n","cluster_labels = kmeans.labels_\n","\n","# Print cluster labels\n","print(\"Cluster labels:\", cluster_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"yxKKDiYZy8fY","executionInfo":{"status":"error","timestamp":1709292961277,"user_tz":-330,"elapsed":3655,"user":{"displayName":"Aathif Aslam","userId":"07585414347874006018"}},"outputId":"ce176087-b1b3-4e0d-bdac-5f59e07a1548"},"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'generate_linear_data' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8af56a778053>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mintercept_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_linear_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslope_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Concatenate features and target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'generate_linear_data' is not defined"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","\n","# Load the trained linear regression model\n","model = LinearRegression()\n","model = joblib.load('linear_regression_model.pkl')\n","\n","# Function to read a downloaded image and preprocess it\n","def preprocess_image(image_path):\n","    # Read the image using cv2.imread()\n","    image = cv2.imread(image_path)\n","    # Convert the image to grayscale\n","    grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    # Flatten the 2D grayscale image into a 1D array\n","    flattened_image = grayscale_image.flatten()\n","    # Reshape the flattened image to have a single feature per row\n","    reshaped_image = flattened_image.reshape(-1, 1)\n","    return reshaped_image\n","\n","# Example usage\n","image_path = '/content/images_output/slide19 (1).jpg'  # Replace 'path_to_downloaded_image.jpg' with the actual path to your downloaded image\n","image = preprocess_image(image_path)\n","\n","# Check if the image was successfully preprocessed\n","if image is not None:\n","    # Apply the machine learning model to the preprocessed image\n","    prediction = model.predict(image)\n","    # Print the prediction\n","    print(\"Prediction:\", prediction)\n","else:\n","    print(\"Failed to preprocess the image.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5trcX9PGwSv","executionInfo":{"status":"ok","timestamp":1709015164101,"user_tz":-330,"elapsed":1154,"user":{"displayName":"Aathif Aslam","userId":"07585414347874006018"}},"outputId":"db85badd-8e10-41e0-a3f7-c3f9ee8ea741"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction: [947.56494023 947.56494023 947.56494023 ...  -2.6334914    1.09277696\n"," 250.75275703]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import os\n","\n","# Function to scrape images from a given website URL\n","def scrape_images(url):\n","    # Send a GET request to the URL\n","    response = requests.get(url)\n","\n","    # Check if the request was successful\n","    if response.status_code == 200:\n","        # Parse the HTML content\n","        soup = BeautifulSoup(response.content, 'html.parser')\n","\n","        # Find all image tags\n","        image_tags = soup.find_all('img')\n","\n","        # Extract image URLs\n","        image_urls = [tag['src'] for tag in image_tags if 'src' in tag.attrs]\n","\n","        return image_urls\n","    else:\n","        print(\"Failed to fetch URL:\", url)\n","\n","# Function to download images\n","def download_images(image_urls, output_dir):\n","    for i, url in enumerate(image_urls):\n","        # Send a GET request to the image URL\n","        response = requests.get(url)\n","\n","        # Check if the request was successful\n","        if response.status_code == 200:\n","            # Write the image content to a file\n","            with open(os.path.join(output_dir, f\"image_{i}.jpg\"), 'wb') as f:\n","                f.write(response.content)\n","        else:\n","            print(\"Failed to download image from URL:\", url)\n","\n","\n","# Create the directory if it does not exist\n","output_directory = 'images_output'\n","if not os.path.exists(output_directory):\n","    os.makedirs(output_directory)\n","\n","# Example usage\n","url = 'https://d138zd1ktt9iqe.cloudfront.net/media/seo_landing_files/revati-f-linear-graph-01-1605708494.png '\n","image_urls = scrape_images(url)\n","if image_urls:\n","    download_images(image_urls, 'images_output')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nnkF1n8t5ZEX","executionInfo":{"status":"ok","timestamp":1709012934851,"user_tz":-330,"elapsed":2527,"user":{"displayName":"Aathif Aslam","userId":"07585414347874006018"}},"outputId":"e72c7ab0-b646-407e-d455-6e0adca9b081"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Failed to fetch URL: https://d138zd1ktt9iqe.cloudfront.net/media/seo_landing_files/revati-f-linear-graph-01-1605708494.png \n"]}]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.linear_model import LinearRegression\n","from sklearn.decomposition import PCA\n","import joblib\n","\n","# Load the trained linear regression model\n","model = joblib.load('linear_regression_model.pkl')\n","\n","# Define desired width and height for resizing the images\n","desired_width = 100\n","desired_height = 100\n","\n","# Function to load and preprocess images from a directory\n","def load_images_from_directory(directory):\n","    images = []\n","    for filename in os.listdir(directory):\n","        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n","            img = cv2.imread(os.path.join(directory, filename))\n","            # Preprocess the image\n","            img_processed = preprocess_image(img)\n","            images.append(img_processed)\n","    return images\n","\n","# Function to preprocess the image\n","def preprocess_image(img):\n","    # Resize the image to the desired dimensions\n","    img_resized = cv2.resize(img, (desired_width, desired_height))\n","    # Flatten the image to a 1D array\n","    img_flat = img_resized.flatten()\n","    return img_flat\n","\n","# Function to apply PCA to images\n","def apply_pca_to_images(images, n_components=1):\n","    pca = PCA(n_components=n_components)\n","    images_pca = pca.fit_transform(images)\n","    return images_pca\n","\n","# Function to apply the machine learning model to images\n","def apply_model_to_images(images):\n","    predictions = []\n","    for img in images:\n","        # Check if the image array needs reshaping\n","        if img.ndim == 1:\n","            img = img.reshape(1, -1)\n","        # Make prediction\n","        prediction = model.predict(img)\n","        predictions.append(prediction)\n","    return predictions\n","\n","\n","# Function to print the output XY coordinates\n","def print_output_coordinates(predictions):\n","    for i, prediction in enumerate(predictions):\n","        # Check if prediction has at least one element\n","        if len(prediction) >= 2:\n","            print(f\"Image {i+1} - X: {prediction[0]}, y: {prediction[1]}\")\n","        else:\n","            print(f\"Image {i+1} - X: {prediction[0]}, y: N/A (insufficient data)\")\n","\n","\n","# Example usage\n","images_directory = 'images_output'\n","images = load_images_from_directory(images_directory)\n","\n","# Apply PCA to images\n","images_pca = apply_pca_to_images(images)\n","\n","# Apply the machine learning model to PCA-transformed images\n","predictions = apply_model_to_images(images_pca)\n","\n","# Print the output XY coordinates\n","print_output_coordinates(predictions)\n"],"metadata":{"id":"O_MKE15uOGUt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import cv2\n","import numpy as np\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Function to create directory if it doesn't exist\n","def create_directory(directory_name):\n","    if not os.path.exists(directory_name):\n","        os.makedirs(directory_name)\n","        print(f\"Directory '{directory_name}' created successfully.\")\n","    else:\n","        print(f\"Directory '{directory_name}' already exists.\")\n","\n","# Function to download images from URLs\n","def download_images(image_urls, output_dir):\n","    for i, url in enumerate(image_urls):\n","        if url.startswith('data:image/svg+xml'):\n","            continue  # Skip SVG images\n","        response = requests.get(url)\n","        with open(f'{output_dir}/graph_{i}.jpg', 'wb') as f:\n","            f.write(response.content)\n","\n","# Function to detect graphs in images\n","def detect_graphs(image_files):\n","    detected_graphs = []\n","    for image_file in image_files:\n","        # Perform image processing and object detection using OpenCV or other libraries\n","        # For example, you can use edge detection to detect the graph boundaries\n","        image = cv2.imread(image_file)\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        edges = cv2.Canny(gray, 50, 150)\n","\n","        # Find contours\n","        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","        # Draw contours on the original image\n","        for contour in contours:\n","            x, y, w, h = cv2.boundingRect(contour)\n","            cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","\n","        # Save the detected graph with contours\n","        output_file = f'detected_images/{os.path.basename(image_file)}'\n","        cv2.imwrite(output_file, image)\n","\n","        # Append the path to the detected image to the list\n","        detected_graphs.append(output_file)\n","\n","    return detected_graphs\n","\n","# Function to annotate detected graphs\n","def annotate_graphs(graph_images):\n","    annotated_data = []\n","    for graph_image in graph_images:\n","        # Perform annotation by detecting data points on the graph\n","        # For example, you can use feature detection techniques to find data points\n","\n","        # Dummy example: Adding random annotated data\n","        num_points = np.random.randint(5, 10)\n","        annotation_data = [(round(np.random.uniform(0, 10), 1), round(np.random.uniform(0, 10), 1)) for _ in range(num_points)]\n","\n","        # Append annotation data to the list\n","        annotated_data.extend(annotation_data)\n","\n","    return annotated_data\n","\n","# Function to save annotation outputs\n","def save_annotations(annotation_data, output_file):\n","    annotation_df = pd.DataFrame(annotation_data, columns=['X', 'Y'])\n","    annotation_df.to_csv(output_file, index=False, float_format='%.1f')\n","\n","# Web scraping\n","url = 'https://www.frontporchmath.com/topics/algebra/graphing-linear-equations/graphing-linear-equations-creating-table-coordinates-video/graphing-linear-equations-2/'  # Replace with the URL of the web page containing graph images\n","response = requests.get(url)\n","soup = BeautifulSoup(response.text, 'html.parser')\n","image_urls = [img['src'] for img in soup.find_all('img')]\n","\n","# Create directory for downloaded images\n","create_directory('downloaded_images')\n","\n","# Download images\n","download_images(image_urls, 'downloaded_images')\n","\n","# Detect graphs in downloaded images\n","detected_graphs = detect_graphs(['downloaded_images/graph_0.jpg'])  # Example with a single image\n","\n","# Annotate detected graphs\n","annotated_data = annotate_graphs(detected_graphs)\n","\n","# Save annotation outputs\n","save_annotations(annotated_data, 'annotation_coordinates.csv')  # Example annotation data\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8xbM6A033V55","executionInfo":{"status":"ok","timestamp":1709495405246,"user_tz":-330,"elapsed":2249,"user":{"displayName":"Aathif Aslam","userId":"07585414347874006018"}},"outputId":"b6f54e82-df7c-46ec-c043-f2bee483530f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Directory 'downloaded_images' already exists.\n"]}]}]}